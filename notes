### Notes:

#### Sept 9 2015:
	Check if the gains from cross validation is significant.
	$sd = \sqrt((0.75*(1-0.75))/7000)
	Binomial Standard Deviation
	This is good for the report to calculate if gains in algorithm were significant

	TODO:
	Graphs for varying size of train/test set
	Why my accuracy is lower
	Relationship between popularity vs naive bayes


### Sept 23 2015

	TODO:
	Vary size of training set and test set
	Generate graph of alpha variying
	Generate graph of epsilon varying
	Generate graph of hashtags to predict varying
	Generate graph of hit range varying
	Install caffee
	Logistic Regression using caffe



### Sept 30 2015

	TODO:
	start writing report
	install caffe
	better graphs
	have graph for vary size of training and test set
	predict out of 500 hashtags, not 56
	50 examples where predicted correct, 50 examples where prediction is incorrect
		for each example compute the top log probabilities. E.g. hashtag is basketball, lebron has high P(hashtag|word)


### Oct 7 2015

	TODO:
	show graphs for the 500 hashtags in range of 5
	show probability results for the actual hashtag in incorrect predictions
	for prediction probability results have hitrange set to 50
	Take the median and average differences between each word for the probability results, show the max, and min for hashtag

### Oct 14 2015

	TODO:
	Compute probabilities without the priors
	Write report for Naive Bayes section
		Start with the reproductino
		Then our fine tuning and show results
	Hopefully logistic regression

### Oct 26 2015
	TODO:
	Try to see if not double counting words make difference in naive bayes
	Save training, test, validation, and outputs as csv
	Use torch and do logistic regression with fully connected model
	If have time, add hidden layer
	REMEMBER to save weights, save outputs.
	Compute the probabilities of each of the inputs to an output unit just like NB


### Dec 14 2015
	TODO:
	Consider mechanical turk ~150-200 people
	Write the report, only include the analysis for log reg and naive bayes


### TODO:
	- Maybe word2vec
	- Insights via predicted hashtag -> top m words associated -> top n hashtags associated
		- Try to find #show -> soyouthinkyoucandance, hellskitchen -> #sucks, #awesome
	- Outputting predictions for naive bayes and logistic regression for mechanical turk
		- get n tweets
			- get top 5 out of 500 predictions from each model
